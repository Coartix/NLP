{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "import functools\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/coartix/.cache/huggingface/modules/datasets_modules/datasets/imdb/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0 (last modified on Fri Mar 17 11:33:19 2023) since it couldn't be found locally at imdb., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset imdb (/home/coartix/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27151b549fda4258b4d0cf69f5cf8ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How many splits does the dataset has?\n",
    "The dataset has 3 splits (training, test, unsupervised).\n",
    "\n",
    "### 2. How big are these splits?\n",
    "train -> 25000 rows  \n",
    "test -> 25000 rows  \n",
    "unsupervised -> 50000 rows  \n",
    "A row contains a text and a value 0 or 1 corresponding respectively to a negative sentiment or a positive one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We will create dataframes to manipulate the data in each splits :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in the future. This film is interesting as an experime...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised as an Australian cult film. The humour is broad, un...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time I will try to explain its virtues to the uninitiat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds his own, are the two greatest comedies to ever be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started life as a satirical comic strip in 'Private Eye', wri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who must go to England if he wishes to claim his inherit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text  \\\n",
       "0      I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded ...   \n",
       "1      \"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's ...   \n",
       "2      If only to avoid making this type of film in the future. This film is interesting as an experime...   \n",
       "3      This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film in...   \n",
       "4      Oh, brother...after hearing about this ridiculous film for umpteen years all I can think of is t...   \n",
       "...                                                                                                    ...   \n",
       "24995  A hit at the time but now better categorised as an Australian cult film. The humour is broad, un...   \n",
       "24996  I love this movie like no other. Another time I will try to explain its virtues to the uninitiat...   \n",
       "24997  This film and it's sequel Barry Mckenzie holds his own, are the two greatest comedies to ever be...   \n",
       "24998  'The Adventures Of Barry McKenzie' started life as a satirical comic strip in 'Private Eye', wri...   \n",
       "24999  The story centers around Barry McKenzie who must go to England if he wishes to claim his inherit...   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "24995      1  \n",
       "24996      1  \n",
       "24997      1  \n",
       "24998      1  \n",
       "24999      1  \n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "df_train = pd.DataFrame(dataset['train'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, und...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Worth the entertainment value of a rental, especially if you like action movies. This one featur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alright action sequences that make the plot seem a li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STAR RATING: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>Just got around to seeing Monster Man yesterday. It had been a long wait and after lots of antic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I got this as part of a competition prize. I watched it, not really expecting much from an obvio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>I got Monster Man in a box set of three films where I mainly wanted the other two but still had ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>Five minutes in, i started to feel how naff this was looking, you've got a completely unheroic h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>I caught this movie on the Sci-Fi channel recently. It actually turned out to be pretty decent a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text  \\\n",
       "0      I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, und...   \n",
       "1      Worth the entertainment value of a rental, especially if you like action movies. This one featur...   \n",
       "2      its a totally average film with a few semi-alright action sequences that make the plot seem a li...   \n",
       "3      STAR RATING: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday ...   \n",
       "4      First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably wi...   \n",
       "...                                                                                                    ...   \n",
       "24995  Just got around to seeing Monster Man yesterday. It had been a long wait and after lots of antic...   \n",
       "24996  I got this as part of a competition prize. I watched it, not really expecting much from an obvio...   \n",
       "24997  I got Monster Man in a box set of three films where I mainly wanted the other two but still had ...   \n",
       "24998  Five minutes in, i started to feel how naff this was looking, you've got a completely unheroic h...   \n",
       "24999  I caught this movie on the Sci-Fi channel recently. It actually turned out to be pretty decent a...   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "24995      1  \n",
       "24996      1  \n",
       "24997      1  \n",
       "24998      1  \n",
       "24999      1  \n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(dataset['test'])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is just a precious little diamond. The play, the script are excellent. I cant compare this ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I say this is my favourite film of all time, that comment is not to be taken lightly. I pro...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I saw this movie because I am a huge fan of the TV series of the same name starring Roy Dupuis a...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Being that the only foreign films I usually like star a Japanese person in a rubber suit who cru...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After seeing Point of No Return (a great movie) and being told that the original was better, I w...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>License To Kill (1989) is an inanely dismal installment to the Bond franchise that is best forgo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>I love watching a James Bond. It's not very intellectual, granted, but it's fun. I know the basi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I can't decide what was the worst thing about this movie. The bad plot, terrible acting, cheesy ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>UGH... As an adorer of the James Bond character, I have to call Timothy Dalton a sacrilege! And ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I do firmly believe that the revue on this film is highly unfair. The \"If You like this try...\" ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text  \\\n",
       "0      This is just a precious little diamond. The play, the script are excellent. I cant compare this ...   \n",
       "1      When I say this is my favourite film of all time, that comment is not to be taken lightly. I pro...   \n",
       "2      I saw this movie because I am a huge fan of the TV series of the same name starring Roy Dupuis a...   \n",
       "3      Being that the only foreign films I usually like star a Japanese person in a rubber suit who cru...   \n",
       "4      After seeing Point of No Return (a great movie) and being told that the original was better, I w...   \n",
       "...                                                                                                    ...   \n",
       "49995  License To Kill (1989) is an inanely dismal installment to the Bond franchise that is best forgo...   \n",
       "49996  I love watching a James Bond. It's not very intellectual, granted, but it's fun. I know the basi...   \n",
       "49997  I can't decide what was the worst thing about this movie. The bad plot, terrible acting, cheesy ...   \n",
       "49998  UGH... As an adorer of the James Bond character, I have to call Timothy Dalton a sacrilege! And ...   \n",
       "49999  I do firmly believe that the revue on this film is highly unfair. The \"If You like this try...\" ...   \n",
       "\n",
       "       label  \n",
       "0         -1  \n",
       "1         -1  \n",
       "2         -1  \n",
       "3         -1  \n",
       "4         -1  \n",
       "...      ...  \n",
       "49995     -1  \n",
       "49996     -1  \n",
       "49997     -1  \n",
       "49998     -1  \n",
       "49999     -1  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unsupervised = pd.DataFrame(dataset['unsupervised'])\n",
    "df_unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is the proportion of each class on the supervised splits?\n",
    "\n",
    "Here is a plot counting the number of each class into train and test splits :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax[0].set_xticks([0, 1])\n",
    "ax[1].set_xticks([0, 1])\n",
    "ax[0].set_yticks([0, df_train['label'].value_counts().max()])\n",
    "ax[1].set_yticks([0, df_test['label'].value_counts().max()])\n",
    "\n",
    "ax[0].hist(df_train['label'])\n",
    "ax[1].hist(df_test['label'])\n",
    "ax[0].set_title('df_train')\n",
    "ax[1].set_title('df_test')\n",
    "ax[0].set_xlabel('label')\n",
    "ax[1].set_xlabel('label')\n",
    "ax[0].set_ylabel('count')\n",
    "ax[1].set_ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_train[\"label\"].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are either 0 or 1. Each classes count up for 12500 on each splits (test and train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will lower the text to not duplicate words that may be the same with capitals.  \n",
    "Some texts contain some html like \"<br \\/>\" or punctuations which are not necessary. <br> Let remove them except for '-' which may be useful to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingString(text: str) -> str:\n",
    "    '''\n",
    "        Preprocessing string\n",
    "        Input:\n",
    "            text: string\n",
    "        Output:\n",
    "            text: string\n",
    "    '''\n",
    "    text = text.lower().replace(\"<br />\", \" \")\n",
    "    for punct in punctuation:\n",
    "        if (not punct in str(\"-\")):\n",
    "            text = text.replace(punct, \" \")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i rented i am curious-yellow from my video store because of all the controversy that surrounded ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am curious  yellow  is a risible and pretentious steaming pile  it doesn t matter what one s ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if only to avoid making this type of film in the future  this film is interesting as an experime...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this film was probably inspired by godard s masculin  féminin and i urge you to see that film in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh  brother   after hearing about this ridiculous film for umpteen years all i can think of is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  i rented i am curious-yellow from my video store because of all the controversy that surrounded ...   \n",
       "1   i am curious  yellow  is a risible and pretentious steaming pile  it doesn t matter what one s ...   \n",
       "2  if only to avoid making this type of film in the future  this film is interesting as an experime...   \n",
       "3  this film was probably inspired by godard s masculin  féminin and i urge you to see that film in...   \n",
       "4  oh  brother   after hearing about this ridiculous film for umpteen years all i can think of is t...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'] = df_train['text'].apply(lambda text: preprocessingString(text))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love sci-fi and am willing to put up with a lot  sci-fi movies tv are usually underfunded  und...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worth the entertainment value of a rental  especially if you like action movies  this one featur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>its a totally average film with a few semi-alright action sequences that make the plot seem a li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>star rating        saturday night      friday night     friday morning    sunday night   monday ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first off let me say  if you haven t enjoyed a van damme movie since bloodsport  you probably wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  i love sci-fi and am willing to put up with a lot  sci-fi movies tv are usually underfunded  und...   \n",
       "1  worth the entertainment value of a rental  especially if you like action movies  this one featur...   \n",
       "2  its a totally average film with a few semi-alright action sequences that make the plot seem a li...   \n",
       "3  star rating        saturday night      friday night     friday morning    sunday night   monday ...   \n",
       "4  first off let me say  if you haven t enjoyed a van damme movie since bloodsport  you probably wi...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['text'] = df_test['text'].apply(lambda text: preprocessingString(text))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Naive Bayes from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNaiveBayes(df: pd.DataFrame, classes: list) -> tuple:\n",
    "    '''\n",
    "        Input:\n",
    "            df: dataframe\n",
    "            classes: list of classes\n",
    "        Output:\n",
    "            log_prior: list of log prior of each class\n",
    "            loglikehood: list of log likehood of each class\n",
    "            vocabulary: set of vocabulary\n",
    "    '''\n",
    "    log_prior = []\n",
    "    loglikehood = []\n",
    "    vocabulary = set(str().join((df['text'])).split(\" \"))\n",
    "    n_doc = df.shape[0]\n",
    "    \n",
    "    for class_c in classes:\n",
    "        n_class = df[df['label'] == class_c].shape[0]\n",
    "        log_prior.append(np.log(n_class / n_doc))\n",
    "        big_doc = str().join((df[df['label'] == class_c]['text'])).split(\" \")\n",
    "        \n",
    "        d = defaultdict(int)\n",
    "        for word in big_doc:\n",
    "           d[word] += 1 \n",
    "        sumcount_v = sum(d.values()) + len(vocabulary)\n",
    "        \n",
    "        loglikehood_c = {}\n",
    "        for word in vocabulary:\n",
    "            loglikehood_c[word] = np.log((d[word] + 1) / sumcount_v)\n",
    "        loglikehood.append(loglikehood_c)\n",
    "    \n",
    "    return log_prior, loglikehood, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikehood, vocabulary = trainNaiveBayes(df_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testNaiveBayes(testdoc: str, logprior: list, loglikehood: list, classes: list, vocabulary: set) -> int:\n",
    "    '''\n",
    "        Input:\n",
    "            testdoc: string\n",
    "            log_prior: list of log prior of each class\n",
    "            loglikehood: list of log likehood of each class\n",
    "            classes: list of classes\n",
    "            vocabulary: set of vocabulary\n",
    "        Output:\n",
    "            class: class of testdoc\n",
    "    '''\n",
    "    probabilty_class = {}\n",
    "    for classes_c in classes:\n",
    "        probabilty_class[classes_c] = logprior[classes_c]\n",
    "        for word in testdoc.split():\n",
    "            if (word in vocabulary):\n",
    "                probabilty_class[classes_c] += loglikehood[classes_c][word]\n",
    "    return np.argmax(list(probabilty_class.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = df_test['text'].apply(lambda text : testNaiveBayes(text, logprior, loglikehood, labels, vocabulary))\n",
    "y_true = df_test['label']\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Naive Bayes from Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81432"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "PipelineNB = Pipeline([('vect', CountVectorizer()), ('clf', MultinomialNB())])\n",
    "PipelineNB.fit(df_train['text'], df_train['label'])\n",
    "\n",
    "y_pred = PipelineNB.predict(df_test['text'])\n",
    "y_true = df_test['label']\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Accuracy report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own implementation - Training set accuracy:  0.90312\n",
      "Own implementation - Test set accuracy:  0.8156\n",
      "Scikit-learn implementation - Training set accuracy:  0.89768\n",
      "Scikit-learn implementation - Test set accuracy:  0.81432\n"
     ]
    }
   ],
   "source": [
    "# Own implementation\n",
    "# Training set\n",
    "y_pred = df_train['text'].apply(lambda text : testNaiveBayes(text, logprior, loglikehood, labels, vocabulary))\n",
    "y_true = df_train['label']\n",
    "print(\"Own implementation - Training set accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Test set\n",
    "y_pred = df_test['text'].apply(lambda text : testNaiveBayes(text, logprior, loglikehood, labels, vocabulary))\n",
    "y_true = df_test['label']\n",
    "print(\"Own implementation - Test set accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Scikit-learn implementation\n",
    "# Training set\n",
    "y_pred = PipelineNB.predict(df_train['text'])\n",
    "y_true = df_train['label']\n",
    "print(\"Scikit-learn implementation - Training set accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Test set\n",
    "y_pred = PipelineNB.predict(df_test['text'])\n",
    "y_true = df_test['label']\n",
    "print(\"Scikit-learn implementation - Test set accuracy: \", accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Most likely, the scikit-learn implementation will give better results. Looking at the documentation, explain why it could be the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This could be explained because the multinomial Naive Bayes classifier is better suited for classification with discrete features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Why is accuracy a sufficient measure of evaluation here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there is only 2 classes so on a test the prediction is either true or false. This is well represented by a proportion of valid and wrong tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Using one of the implementation, take at least 2 wrongly classified example from the test set and try explaining why the model failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use our own implementation and show two texts where the implementation failed to predict the right class :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>blind date  columbia pictures  1934   was a decent film  but i have a few issues with this film  first of all  i don t fault the actors in this film at all  but more or less  i have a problem with the script  also  i understand that this film was made in the 1930 s and people were looking to escape reality  but the script made ann sothern s character look weak  she kept going back and forth between suitors and i felt as though she should have stayed with paul kelly s character in the end  he truly did care about her and her family and would have done anything for her and he did by giving her up in the end to fickle neil hamilton who in my opinion was only out for a good time  paul kelly s character  although a workaholic was a man of integrity and truly loved kitty  ann sothern  as opposed to neil hamilton  while he did like her a lot  i didn t see the depth of love that he had for her character  the production values were great  but the script could have used a little work</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>i caught this movie on the sci-fi channel recently  it actually turned out to be pretty decent as far as b-list horror suspense films go  two guys  one naive and one loud mouthed a    take a road trip to stop a wedding but have the worst possible luck when a maniac in a freaky  make-shift tank truck hybrid decides to play cat-and-mouse with them  things are further complicated when they pick up a ridiculously whorish hitchhiker  what makes this film unique is that the combination of comedy and terror actually work in this movie  unlike so many others  the two guys are likable enough and there are some good chase suspense scenes  nice pacing and comic timing make this movie more than passable for the horror slasher buff  definitely worth checking out</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                text  \\\n",
       "11     blind date  columbia pictures  1934   was a decent film  but i have a few issues with this film  first of all  i don t fault the actors in this film at all  but more or less  i have a problem with the script  also  i understand that this film was made in the 1930 s and people were looking to escape reality  but the script made ann sothern s character look weak  she kept going back and forth between suitors and i felt as though she should have stayed with paul kelly s character in the end  he truly did care about her and her family and would have done anything for her and he did by giving her up in the end to fickle neil hamilton who in my opinion was only out for a good time  paul kelly s character  although a workaholic was a man of integrity and truly loved kitty  ann sothern  as opposed to neil hamilton  while he did like her a lot  i didn t see the depth of love that he had for her character  the production values were great  but the script could have used a little work    \n",
       "24999                                                                                                                                                                                                                                       i caught this movie on the sci-fi channel recently  it actually turned out to be pretty decent as far as b-list horror suspense films go  two guys  one naive and one loud mouthed a    take a road trip to stop a wedding but have the worst possible luck when a maniac in a freaky  make-shift tank truck hybrid decides to play cat-and-mouse with them  things are further complicated when they pick up a ridiculously whorish hitchhiker  what makes this film unique is that the combination of comedy and terror actually work in this movie  unlike so many others  the two guys are likable enough and there are some good chase suspense scenes  nice pacing and comic timing make this movie more than passable for the horror slasher buff  definitely worth checking out    \n",
       "\n",
       "       label  \n",
       "11         0  \n",
       "24999      1  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = df_test['text'].apply(lambda text : testNaiveBayes(text, logprior, loglikehood, labels, vocabulary))\n",
    "y_true = df_test['label']\n",
    "\n",
    "df_wrong_pred = df_test[y_true != y_pred]\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df_wrong_pred.iloc[[0, -1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is two examples where the program should have return a class 0 and 1 (negative, positive).  \n",
    "  \n",
    "-> The first one is ... \n",
    "  \n",
    "-> The second text is ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. [BONUS] What are the top 10 most important words (features) for each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/coartix/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  0\n",
      "['', 'the', 'a', 'and', 'of', 'to', 'is', 'it', 'i', 'in', 'this', 'that', 's', 'was', 'movie', 'for', 'but', 'with', 'as', 't', 'film', 'you', 'on', 'not', 'have', 'are', 'be', 'he', 'they', 'one', 'at', 'his', 'all', 'so', 'like', 'there', 'just', 'by', 'or', 'an', 'who', 'from', 'if', 'about', 'out', 'what', 'some', 'no', 'her', 'even', 'can', 'has', 'good', 'bad', 'would', 'only', 'more', 'when', 'up', 'she', 'really', 'had', 'were', 'time', 'my', 'very', 'which', 'me', 'see', 'don', 'we', 'their', 'do', 'than', 'story', 'been', 'much', 'get', 'because', '-', 'people', 'then', 'could', 'how', 'any', 'make', 'into', 'made', 'other', 'first', 'them', 'too', 'plot', 'movies', 'acting', 'will', 'way', 'most', 'well', 'him']\n",
      "\n",
      "Class:  1\n",
      "['', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i', 'that', 'this', 's', 'as', 'with', 'for', 'was', 'but', 'film', 'movie', 'his', 'on', 'you', 'he', 'are', 'not', 't', 'one', 'have', 'be', 'by', 'all', 'who', 'an', 'at', 'from', 'her', 'they', 'has', 'so', 'like', 'about', 'very', 'there', 'out', 'she', 'or', 'what', 'good', 'more', 'when', 'some', 'if', 'just', 'can', 'story', 'my', 'great', 'which', 'time', 'their', 'see', 'up', 'well', 'also', 'we', 'really', 'would', 'will', 'had', 'me', 'only', 'him', 'even', 'most', 'other', '-', 'were', 'than', 'much', 'first', 'its', 'into', 'people', 'no', 'best', 'get', 'love', 'how', 'been', 'because', 'way', 'life', 'do', 'them', 'films', 'after', 'many', 'made', 'think']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the most important words for each class\n",
    "def getImportantWords(loglikehood, classes, vocabulary):\n",
    "    '''\n",
    "        Input:\n",
    "            loglikehood: list of log likehood of each class\n",
    "            classes: list of classes\n",
    "            vocabulary: set of vocabulary\n",
    "        Output:\n",
    "            important_words: dictionary of important words for each class\n",
    "    '''\n",
    "    important_words = {}\n",
    "    for classes_c in classes:\n",
    "        important_words[classes_c] = sorted(loglikehood[classes_c], key=loglikehood[classes_c].get, reverse=True)[:100]\n",
    "    return important_words\n",
    "\n",
    "importantWords = getImportantWords(loglikehood, labels, vocabulary)\n",
    "for classes_c in labels:\n",
    "    print(\"Class: \", classes_c)\n",
    "    print(importantWords[classes_c])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  0\n",
      "['', 'movie', 'film', 'one', 'like', 'even', 'good', 'bad', 'would', 'really', 'time', 'see', 'story', 'much', 'get', '-', 'people', 'could', 'make', 'made', 'first', 'plot', 'movies', 'acting', 'way', 'well']\n",
      "\n",
      "Class:  1\n",
      "['', 'film', 'movie', 'one', 'like', 'good', 'story', 'great', 'time', 'see', 'well', 'also', 'really', 'would', 'even', '-', 'much', 'first', 'people', 'best', 'get', 'love', 'way', 'life', 'films', 'many', 'made', 'think']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def removeStopWords(importantWords):\n",
    "    '''\n",
    "        Input:\n",
    "            importantWords: dictionary of important words for each class\n",
    "        Output:\n",
    "            importantWords: dictionary of important words for each class\n",
    "    '''\n",
    "    for classes_c in labels:\n",
    "        importantWords[classes_c] = [word for word in importantWords[classes_c] if word not in stops]\n",
    "    return importantWords\n",
    "\n",
    "importantWords = removeStopWords(importantWords)\n",
    "for classes_c in labels:\n",
    "    print(\"Class: \", classes_c)\n",
    "    print(importantWords[classes_c])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the most important words for each class that brings the decision to likely select the class it corresponds to. In class 1 we can see that the word 'love' or 'great' makes the decision favorable towards this class because it doesnt appear in the class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Adding stemming to pretreatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/coartix/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def stemmingPreProcessing(text):\n",
    "    '''\n",
    "        Input:\n",
    "            text: string\n",
    "        Output:\n",
    "            text: string after stemming\n",
    "    '''\n",
    "    re_word = re.compile(r\"^\\w+$\")\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed = [stemmer.stem(word) for word in word_tokenize(text.lower().replace(\"<br />\", \"\")) if re_word.match(word)]\n",
    "    return \" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i rent i am from my video store becaus of all the controversi that surround it when it was first...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i am curious yellow is a risibl and pretenti steam pile it doe matter what one polit view are be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if onli to avoid make this type of film in the futur this film is interest as an experi but tell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this film was probabl inspir by godard masculin féminin and i urg you to see that film film has ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh brother after hear about this ridicul film for umpteen year all i can think of is that old pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  i rent i am from my video store becaus of all the controversi that surround it when it was first...   \n",
       "1  i am curious yellow is a risibl and pretenti steam pile it doe matter what one polit view are be...   \n",
       "2  if onli to avoid make this type of film in the futur this film is interest as an experi but tell...   \n",
       "3  this film was probabl inspir by godard masculin féminin and i urg you to see that film film has ...   \n",
       "4  oh brother after hear about this ridicul film for umpteen year all i can think of is that old pe...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the train dataframe after stemming\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "df_train = pd.DataFrame(dataset['train'])\n",
    "df_train['text'] = df_train['text'].apply(lambda text: stemmingPreProcessing(text))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love and am will to put up with a lot are usual underfund and misunderstood i tri to like this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worth the entertain valu of a rental especi if you like action movi this one featur the usual ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it a total averag film with a few action sequenc that make the plot seem a littl better and remi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>star rate saturday night friday night friday morn sunday night monday morn former new orlean hom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first off let me say if you have enjoy a van damm movi sinc bloodsport you probabl will not like...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  i love and am will to put up with a lot are usual underfund and misunderstood i tri to like this...   \n",
       "1  worth the entertain valu of a rental especi if you like action movi this one featur the usual ca...   \n",
       "2  it a total averag film with a few action sequenc that make the plot seem a littl better and remi...   \n",
       "3  star rate saturday night friday night friday morn sunday night monday morn former new orlean hom...   \n",
       "4  first off let me say if you have enjoy a van damm movi sinc bloodsport you probabl will not like...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the test dataframe after stemming\n",
    "df_test = pd.DataFrame(dataset['test'])\n",
    "df_test['text'] = df_test['text'].apply(lambda text: stemmingPreProcessing(text))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train and evaluate your model again with these pretreatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the stemmed data\n",
    "logprior, loglikehood, vocabulary = trainNaiveBayes(df_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own implementation (Stemming) - Training set accuracy:  0.8776\n",
      "Own implementation (Stemming) - Test set accuracy:  0.79944\n"
     ]
    }
   ],
   "source": [
    "# Testing the train set\n",
    "y_pred = df_train['text'].apply(lambda text : testNaiveBayes(text, logprior, loglikehood, labels, vocabulary))\n",
    "y_true = df_train['label']\n",
    "print(\"Own implementation (Stemming) - Training set accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "# Testing the test set\n",
    "y_pred = df_test['text'].apply(lambda text : testNaiveBayes(text, logprior, loglikehood, labels, vocabulary))\n",
    "y_true = df_test['label']\n",
    "print(\"Own implementation (Stemming) - Test set accuracy: \", accuracy_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Are the results better or worse? Try explaining why the accuracy changed.  \n",
    "  \n",
    "The results show the stemming process to be less effective.  \n",
    "The accuracy changed because the stemming pretreatment shorten words so that we don't have multiple occurence of the same word which could take multiple forms like 'enjoy', 'enjoys', 'enjoyed', 'enjoying'. Those are all grouped and written as 'enjoy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  0\n",
      "['movi', 'film', 'one', 'like', 'make', 'would', 'even', 'get', 'bad', 'good', 'watch', 'time', 'charact', 'onli', 'see', 'realli', 'veri', 'could', 'look', 'doe', 'stori', 'scene', 'act', 'much', 'becaus', 'go', 'end', 'peopl', 'ani', 'thing', 'think', 'made', 'seem', 'show', 'say']\n",
      "\n",
      "Class:  1\n",
      "['film', 'movi', 'one', 'like', 'veri', 'time', 'good', 'see', 'stori', 'charact', 'make', 'get', 'great', 'watch', 'love', 'well', 'would', 'show', 'realli', 'also', 'onli', 'even', 'play', 'doe', 'scene', 'much', 'first', 'peopl', 'end', 'way', 'think', 'best', 'go', 'becaus', 'look']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importantWords = getImportantWords(loglikehood, labels, vocabulary)\n",
    "importantWords = removeStopWords(importantWords)\n",
    "for classes_c in labels:\n",
    "    print(\"Class: \", classes_c)\n",
    "    print(importantWords[classes_c])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
