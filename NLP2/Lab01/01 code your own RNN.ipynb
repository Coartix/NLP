{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "780cf295-7141-43e8-b8b8-199b14071e2a",
   "metadata": {},
   "source": [
    "# Coding your own RNN\n",
    "\n",
    "Using this pre-filled notebook, we will code our own RNN for sentence classification. For now, we'll keep using IMDB, as the goal of this part is to understand how an RNN works.\n",
    "\n",
    "Unlike our previous lab, we will also learn the embedding layer. Which means we need to deal with vocabulary by ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f26c411e-1cd5-4a1c-9b3d-de16e26db901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Callable, Dict, Generator, List, Tuple\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.vocab import vocab, Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "import copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec040734-ff61-4c85-982c-acb2a5bd6d8c",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We load the dataset and split the training set in a stratified train/validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42b598f9-36b5-43e3-bb25-488b0fb53aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/coartix/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd63e1798c0047bea9baeeca04a0b3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /home/coartix/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-5f37fd0866e4f89f.arrow and /home/coartix/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0/cache-dd5732a0e6ac784c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20000, 2), (5000, 2), (25000, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "train_dataset = dataset[\"train\"].train_test_split(\n",
    "    stratify_by_column=\"label\", test_size=0.2, seed=42\n",
    ")\n",
    "test_df = dataset[\"test\"]\n",
    "train_df = train_dataset[\"train\"]\n",
    "valid_df = train_dataset[\"test\"]\n",
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f309e444-d52d-4f87-8d18-7bb470b7cfcd",
   "metadata": {},
   "source": [
    "## Vocabulary (1 point)\n",
    "\n",
    "**\\[1 point\\]** Build your own vocabulary. The [example provided in torchtext documentation](https://pytorch.org/text/stable/vocab.html#id1) might be of help.\n",
    "* Don't forge to setup the `min_freq` parameter to not include unfrequent noise.\n",
    "* You will need a tokenizer. Reuse the `basic_english` one from the our previous lab.\n",
    "* For an RNN we need two special tokens: `<unk>`, for unknown words, and `<pad>` for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152b550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f77c04e25cd48f78929d36cfb247c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_freq = 5\n",
    "tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n",
    "\n",
    "tokens = []\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "for text in tqdm(train_df['text'], total=len(train_df)):\n",
    "    tokens += tokenizer(text)\n",
    "vocabulary = vocab(OrderedDict(sorted(Counter(tokens).items(), key=lambda x: x[1], reverse=True)), min_freq=min_freq, specials=[pad_token, unk_token])\n",
    "vocabulary.set_default_index(vocabulary[unk_token])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c66facfa",
   "metadata": {},
   "source": [
    "Testing the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e495aa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 1 2\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary['<unk>'], vocabulary['<pad>'], vocabulary['out of vocabulary'], vocabulary['the'])\n",
    "# get the word at index 2 in vocab\n",
    "print(vocabulary.get_itos()[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89386d66-f758-4d87-b786-9d570eb22f2f",
   "metadata": {},
   "source": [
    "## Vectorize and batch the input (3 points)\n",
    "\n",
    "As seen in class, our model should take one-hot encoded vectors corresponding to the each token vocabulary id. However, computing a vector x matrix multiplication for every input is unnecessarily costly. Multiplying a one-hot vector with a matrix is the equivalent of taking one row of the matrix. In pyTorch, we provide ids for each token which will be used as input to an `nn.Embedding` layer. The id is simply the row in the embedding matrix.\n",
    "\n",
    "**\\[1 point\\]** Fill the `vectorize_text` function returning a 1D torch tensor of `torch.long` for each input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f6fc4eb-2f25-43ee-8b2f-a9154545ebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(\n",
    "    text: str, vocabulary: Vocab, tokenizer: Callable[[str], List[str]]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate a tensor of vocabluary IDs for a given text.\n",
    "    Args:\n",
    "        text: the input text.\n",
    "        vocabulary: a Vocab objects.\n",
    "        tokenizer: a text tokenizer.\n",
    "    Returns:\n",
    "        A tensor of IDs (torch.long).\n",
    "    \"\"\"\n",
    "    return torch.tensor(\n",
    "        [vocabulary[token] for token in tokenizer(text)], dtype=torch.long\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e1d1865",
   "metadata": {},
   "source": [
    "Testing `vectorize_text` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5040173f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  14,   10,    6, 2148])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "vectorize_text(\"This is a test\", vocabulary, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4a9058-ad04-43b9-bf5c-680afb44e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = partial(vectorize_text, vocabulary=vocabulary, tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9717208d-2f50-4d16-b170-904beeeb71ad",
   "metadata": {},
   "source": [
    "Check the function is working correctly, especially it should return the right special id for unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9727204a-ecff-4e4d-a316-543865d52a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  56, 3160,   13,  244,  526,   50,    3,    3,    3,    1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pipeline(\"Some text I am thinking about... ragafqfa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97eb948c-cfae-47b1-b8ce-bafa358afe65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dae103a2a26456199a0eb40d0189dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a3331c50f046b7bc393010d4cda08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b276887e8f084964aea8551c8b50a0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = [text_pipeline(text) for text in tqdm(train_df[\"text\"])]\n",
    "y_train = train_df[\"label\"]\n",
    "X_valid = [text_pipeline(text) for text in tqdm(valid_df[\"text\"])]\n",
    "y_valid = valid_df[\"label\"]\n",
    "X_test = [text_pipeline(text) for text in tqdm(test_df[\"text\"])]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67138763-f848-4dd7-9036-68df352d22a0",
   "metadata": {},
   "source": [
    "To speed up the training process, we turn the inputs into batches, as we did last time. For batches to work, every line must have the same lengths. Last time, it was implicit as only a vector (the average of all embeddings) was provided. This time, every line has the length of a different review.\n",
    "\n",
    "To go around this problem, we use padding. So every line within a batch is padded to the length of its longest element.\n",
    "\n",
    "* **\\[1 point\\]** Fill the data generator function.\n",
    "* **\\[1 point\\]** On which side should you pad and why?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "025484c9",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks (RNNs) process sequences step-by-step, starting from the left. \n",
    "By right-padding (padding tokens added at the end) the sequences, you ensure that the words in each sentence remain in their original order. This maintains the sequential structure of the sentences, which is essential for capturing meaningful patterns and dependencies in natural language processing tasks.  \n",
    "But, if we use Pytorch RNN which we will in the second notebook, there is a reason for left-padding in PyTorch RNNs. The underlying implementation of these modules assumes that the input sequences are left-padded. Consequently, when you use left-padding, PyTorch can optimize the computations and memory usage during the forward and backward passes of the RNN.  \n",
    "\n",
    "So we will use right-padding here and left-padding on the second notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a88dd162-8107-4f05-bc8a-2fd313a3b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(\n",
    "    X: List[torch.tensor], y: List[int], pad_id: int, batch_size: int = 32\n",
    ") -> Generator[Tuple[torch.Tensor, torch.Tensor], None, None]:\n",
    "    \"\"\"\n",
    "    Yield batches from given input data and labels.\n",
    "    Args:\n",
    "        X: a list of tensor (input features).\n",
    "        y: the corresponding labels.\n",
    "        batch_size: the size of every batch [32].\n",
    "    Returns:\n",
    "        A tuple of tensors (features, labels).\n",
    "    \"\"\"\n",
    "    n_samples = len(X)\n",
    "    n_batches = n_samples // batch_size\n",
    "    for i in range(n_batches):\n",
    "        X_batch = X[i * batch_size : (i + 1) * batch_size]\n",
    "        y_batch = y[i * batch_size : (i + 1) * batch_size]\n",
    "        max_len = max([len(x) for x in X_batch])\n",
    "        X_batch = torch.stack(\n",
    "            [torch.cat((x, torch.tensor([pad_id] * (max_len - len(x))))) for x in X_batch]\n",
    "        )\n",
    "        yield X_batch, torch.tensor(y_batch, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2e10342-4d6b-45c4-8e05-68ef6375b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = lambda: data_generator(X_train, y_train, vocabulary[pad_token])\n",
    "valid_gen = lambda: data_generator(X_valid, y_valid, vocabulary[pad_token])\n",
    "test_gen = lambda: data_generator(X_test, y_test, vocabulary[pad_token])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4489d625-f1ad-49ea-8b54-74463e04877f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Classifier (3 points)\n",
    "\n",
    "**\\[3 points\\]** Code your own RNN. Fill the `RNN` class correctly. Remember an RNN has 3 matrices and an embedding layer (see course slide 61).\n",
    "* The embedding layer turns a one-hot vectors into dense vectors.\n",
    "* The first matrix (W) connects the embedding to the hidden layer.\n",
    "  * `embedding_size -> hidden_size`\n",
    "* The second matrix (U) connect the previous hidden layer to the current one.\n",
    "  * `hidden_size -> hidden_size`\n",
    "* These to vectors are added and go through an activation function (e.g. $h_t = tanh(Wx_i+Uh_{t-1})$).\n",
    "* The last matrix (V) connects the hidden layer to the hidden layer to the output.\n",
    "  * `hidden_size -> 1`\n",
    "* Donc forget to add an `init_hidden` function which initialize the first hidden layer to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a0e7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN customed\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.output_size = 1\n",
    "        \n",
    "        # Define the layers\n",
    "        self.i2h = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x, hidden_state) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns computed output and tanh(i2h + h2h)\n",
    "        Inputs\n",
    "        ------\n",
    "        x: Input vector\n",
    "        hidden_state: Previous hidden state\n",
    "        Outputs\n",
    "        -------\n",
    "        out: Linear output (without activation because of how pytorch works)\n",
    "        hidden_state: New hidden state matrix\n",
    "        \"\"\"\n",
    "        x = self.i2h(x.T)\n",
    "        hidden_state = self.h2h(hidden_state)\n",
    "        hidden_state = torch.tanh(x + hidden_state)\n",
    "        out = self.h2o(hidden_state)\n",
    "        return out, hidden_state\n",
    "        \n",
    "    def init_hidden(self, batch_size=1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\t\t\t\tHelper function.\n",
    "        Returns a hidden state with specified batch size. Defaults to 1\n",
    "        \"\"\"\n",
    "        return torch.zeros(batch_size, self.hidden_size, requires_grad=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c665df6-ff9a-4b66-80fe-8abe62d895c9",
   "metadata": {},
   "source": [
    "## Training (2 points)\n",
    "\n",
    "Training is a bit different than usual. We will need to sequentially (but in \"batch parallel\") go through an input, keeping track of the hidden layer, and use the last output as prediction.\n",
    "\n",
    "**\\[2 point\\]** Code the training loop.\n",
    "* Note that for each batch, you need to loop through the whole input and use the output of the last token as input to your criterion.\n",
    "* Keep the best model evaluated on the validation set.\n",
    "* Plot the training and validation losses.\n",
    "* Training will take some time (~30 min on a T4 GPU). Make sure your results appear in the notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d768c31",
   "metadata": {},
   "source": [
    "Since it can take long, let's try to use cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e9053b8-19f3-45b4-a434-2f8cef8a1f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bff25d28",
   "metadata": {},
   "source": [
    "Defining variables and a method computing the accuracy from predictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46cdc558-249b-4c26-b1e5-fc1c0a78d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embedding = 32\n",
    "n_hidden = 64\n",
    "model = RNN(len(vocabulary.get_itos()), n_embedding, n_hidden).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83345c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Compute the accuracy of a model.\n",
    "    Args:\n",
    "        y_pred: the predictions of the model.\n",
    "        y_true: the true labels.\n",
    "    Returns:\n",
    "        The accuracy of the model.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        y_pred = torch.round(y_pred)\n",
    "        return (y_pred == y_true).sum().item() / len(y_true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bf386e22",
   "metadata": {},
   "source": [
    "Let's begin the training of the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11753231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6fee9c51224b44bff15fda9a11b7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m l\n\u001b[1;32m     31\u001b[0m \u001b[39m# 4. Compte gradients gradients\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     34\u001b[0m \u001b[39m# 5. Adjust learnable parameters\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m# clip as well to avoid vanishing and exploding gradients\u001b[39;00m\n\u001b[1;32m     36\u001b[0m nn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 32\n",
    "train_losses = {}\n",
    "best_model = None\n",
    "accuracy_list = []\n",
    "for epoch in range(n_epochs):\n",
    "    epoch_losses = list()\n",
    "    model.train()\n",
    "    for (X_batch, y_batch) in tqdm(train_gen()):\n",
    "        if X_batch.shape[0] != batch_size:\n",
    "            continue\n",
    "        # Set model to train mode\n",
    "        model.train()\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        hidden = model.init_hidden(X_batch.size(0))  # Using dynamic batch size\n",
    "        # To device\n",
    "        X_batch, y_batch, hidden = X_batch.to(device), y_batch.to(device), hidden.to(device)\n",
    "\n",
    "        loss = 0\n",
    "        for c in range(X_batch.shape[1]):\n",
    "            out, hidden = model(X_batch[:, c].reshape(X_batch.shape[0], 1).float(), hidden)\n",
    "            l = criterion(out, y_batch.reshape(X_batch.shape[0], 1).float())\n",
    "            loss += l\n",
    "\n",
    "        # 4. Compute gradients gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Adjust learnable parameters and clip to avoid vanishing and exploding gradients\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.detach().item() / X_batch.shape[1])\n",
    "        accuracy_list.append(accuracy(out, y_batch.reshape(X_batch.shape[0], 1).float()))\n",
    "\n",
    "    train_losses[epoch] = torch.tensor(epoch_losses).mean()\n",
    "    print(f'=> epoch: {epoch + 1}, loss: {train_losses[epoch]}')\n",
    "    print(f'=> epoch: {epoch + 1}, accuracy: {torch.tensor(accuracy_list).mean()}')\n",
    "\n",
    "    # compute validation loss, keep the best model\n",
    "    model.eval()\n",
    "    accuracy_list = []\n",
    "    with torch.no_grad():\n",
    "        valid_losses = list()\n",
    "        for X_batch, y_batch in tqdm(valid_gen()):\n",
    "            if X_batch.shape[0] != batch_size:\n",
    "                continue\n",
    "            hidden = model.init_hidden(X_batch.size(0))\n",
    "            X_batch, y_batch, hidden = X_batch.to(device), y_batch.to(device), hidden.to(device)\n",
    "\n",
    "            loss = 0\n",
    "            for c in range(X_batch.shape[1]):\n",
    "                out, hidden = model(X_batch[:, c].reshape(X_batch.shape[0], 1).float(), hidden)\n",
    "                l = criterion(out, y_batch.reshape(X_batch.shape[0], 1).float())\n",
    "                loss += l\n",
    "\n",
    "            valid_losses.append(loss.detach().item() / X_batch.shape[1])\n",
    "            accuracy_list.append(accuracy(out, y_batch.reshape(X_batch.shape[0], 1).float()))\n",
    "\n",
    "        valid_loss = torch.tensor(valid_losses).mean()\n",
    "        print(f'=> epoch: {epoch + 1}, validation loss: {valid_loss}')\n",
    "        print(f'=> epoch: {epoch + 1}, validation accuracy: {torch.tensor(accuracy_list).mean()}')\n",
    "        if epoch == 0:\n",
    "            best_model = copy.deepcopy(model)\n",
    "        elif valid_loss < min(valid_losses):\n",
    "            best_model = copy.deepcopy(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca3b06dd",
   "metadata": {},
   "source": [
    "Now let's test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b237ae6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Test the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_model\u001b[39m.\u001b[39;49meval()\n\u001b[1;32m      3\u001b[0m accuracy_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "best_model.eval()\n",
    "accuracy_list = []\n",
    "with torch.no_grad():\n",
    "    test_losses = list()\n",
    "    for X_batch, y_batch in tqdm(test_gen()):\n",
    "        if X_batch.shape[0] != batch_size:\n",
    "            continue\n",
    "        hidden = best_model.init_hidden(X_batch.size(0))\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "\n",
    "        loss = 0\n",
    "        for c in range(X_batch.shape[1]):\n",
    "            out, hidden = best_model(X_batch[:, c].reshape(X_batch.shape[0], 1).float(), hidden)\n",
    "            l = criterion(out, y_batch.reshape(X_batch.shape[0], 1).float())\n",
    "            loss += l\n",
    "\n",
    "        test_losses.append(loss.detach().item() / X_batch.shape[1])\n",
    "        accuracy_list.append(accuracy(out, y_batch.reshape(X_batch.shape[0], 1).float()))\n",
    "\n",
    "    test_loss = torch.tensor(test_losses).mean()\n",
    "    print(f'=> test loss: {test_loss}')\n",
    "    print(f'=> test accuracy: {torch.tensor(accuracy_list).mean()}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "137dc500-ece2-4efa-8207-758a5f428c26",
   "metadata": {},
   "source": [
    "## Evaluation (1 point)\n",
    "\n",
    "* **\\[1 point\\]** Compute the accuracy for all 3 splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4544dfd-7567-4bea-b484-490b6a7b74e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> test accuracy: nan\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_accuracies = list()\n",
    "    for X_batch, y_batch in test_gen():\n",
    "        if X_batch.shape[0] != batch_size:\n",
    "            continue\n",
    "        hidden = best_model.init_hidden(X_batch.size(0))\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        hidden = hidden.to(device)\n",
    "\n",
    "        loss = 0\n",
    "        for c in range(X_batch.shape[1]):\n",
    "            out, hidden = best_model(X_batch[:, c].reshape(X_batch.shape[0], 1).float(), hidden)\n",
    "            l = criterion(out, y_batch.reshape(X_batch.shape[0], 1).float())\n",
    "            loss += l\n",
    "\n",
    "        test_accuracies.append(accuracy(out, y_batch.reshape(X_batch.shape[0], 1).float()))\n",
    "\n",
    "    test_accuracy = torch.tensor(test_accuracies).mean()\n",
    "    print(f'=> test accuracy: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
